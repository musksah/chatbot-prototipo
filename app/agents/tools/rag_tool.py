"""
RAG Tool - B√∫squeda sem√°ntica en la base de conocimiento de Cootradecun
"""
from typing import Dict
from langchain.tools import tool
import chromadb
from chromadb.config import Settings
import logging
import re
from pathlib import Path

logger = logging.getLogger(__name__)

# Cliente global de ChromaDB (in-memory para el prototipo)
chroma_client = None
collection = None


def initialize_rag():
    """Inicializa ChromaDB y la colecci√≥n con datos de ejemplo"""
    global chroma_client, collection
    
    try:
        chroma_client = chromadb.Client(Settings(
            anonymized_telemetry=False,
            allow_reset=True
        ))
        
        # Crear o obtener colecci√≥n
        collection = chroma_client.get_or_create_collection(
            name="cootradecun_faqs",
            metadata={"description": "FAQs y documentaci√≥n de Cootradecun"}
        )
        
        # Agregar datos de ejemplo si la colecci√≥n est√° vac√≠a
        if collection.count() == 0:
            _load_sample_data()
            
        logger.info(f"RAG inicializado: {collection.count()} documentos cargados")
        
    except Exception as e:
        logger.error(f"Error inicializando RAG: {e}")
        raise


def _parse_markdown_faqs(markdown_path: Path) -> list:
    """
    Parsea un archivo markdown y extrae los FAQs.
    
    Formato esperado:
    ## T√≠tulo del FAQ
    Contenido del FAQ...
    **Categor√≠a**: categoria
    **Tema**: tema
    ---
    
    Args:
        markdown_path: Ruta al archivo markdown
    
    Returns:
        Lista de diccionarios con id, text, metadata
    """
    try:
        with open(markdown_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Dividir por separadores ---
        sections = content.split('---')
        faqs = []
        faq_counter = 0
        
        for section in sections:
            section = section.strip()
            if not section:
                continue
            
            # Si la secci√≥n empieza con '# ' (cabecera principal), extraer solo la parte despu√©s
            if section.startswith('# '):
                # Buscar donde empieza el primer ## dentro de esta secci√≥n
                parts = section.split('\n## ', 1)
                if len(parts) > 1:
                    section = '## ' + parts[1]  # Mantener el ## al inicio
                else:
                    continue  # No hay FAQs en esta secci√≥n
            
            # Buscar secciones que empiecen con ##
            if not section.startswith('##'):
                continue
            
            faq_counter += 1
            
            # Extraer t√≠tulo (## T√≠tulo)
            title_match = re.search(r'##\s+(.+)', section)
            if not title_match:
                continue
            
            title = title_match.group(1).strip()
            
            # Extraer contenido (texto entre t√≠tulo y metadatos)
            # Primero intentar con metadatos
            content_match = re.search(r'##.+?\n\n(.+?)\n\n\*\*', section, re.DOTALL)
            if not content_match:
                # Si no hay metadatos, tomar todo despu√©s del t√≠tulo hasta el final
                content_match = re.search(r'##.+?\n\n(.+?)(?:\n\n\*\*|\Z)', section, re.DOTALL)
            
            if not content_match:
                logger.warning(f"No se pudo extraer contenido de: {title}")
                continue
            
            text = content_match.group(1).strip()
            
            # Extraer metadatos (opcional)
            category_match = re.search(r'\*\*Categor√≠a\*\*:\s*(.+)', section)
            topic_match = re.search(r'\*\*Tema\*\*:\s*(.+)', section)
            
            category = category_match.group(1).strip() if category_match else "general"
            topic = topic_match.group(1).strip() if topic_match else "general"
            
            # Combinar t√≠tulo y contenido para mejor b√∫squeda sem√°ntica
            # Esto ayuda a que el RAG encuentre el contenido cuando se pregunta por el t√≠tulo
            full_text = f"{title}\n\n{text}"
            
            logger.info(f"Parseado FAQ #{faq_counter}: {title} | Categor√≠a: {category}")
            
            faqs.append({
                "id": f"faq_{faq_counter}",
                "title": title,
                "text": full_text,  # Ahora incluye el t√≠tulo
                "metadata": {
                    "category": category,
                    "topic": topic,
                    "title": title
                }
            })
        
        return faqs
        
    except Exception as e:
        logger.error(f"Error parseando archivo markdown: {e}", exc_info=True)
        return []


def _load_sample_data():
    """Carga datos desde archivo markdown en ChromaDB"""
    # Ruta al archivo de FAQs
    markdown_path = Path(__file__).parent.parent.parent / "data" / "faqs_cootradecun.md"
    
    if not markdown_path.exists():
        logger.warning(f"Archivo de FAQs no encontrado: {markdown_path}")
        logger.warning("Creando datos de ejemplo b√°sicos...")
        # Fallback a datos b√°sicos
        sample_faqs = [{
            "id": "faq_1",
            "text": "Cootradecun es una cooperativa de trabajadores de Cundinamarca.",
            "metadata": {"category": "general", "topic": "info"}
        }]
    else:
        # Parsear el archivo markdown
        sample_faqs = _parse_markdown_faqs(markdown_path)
        logger.info(f"‚úÖ Parseados {len(sample_faqs)} FAQs desde {markdown_path.name}")
    
    if not sample_faqs:
        logger.error("No se pudieron cargar FAQs")
        return
    
    # Insertar en ChromaDB
    collection.add(
        ids=[faq["id"] for faq in sample_faqs],
        documents=[faq["text"] for faq in sample_faqs],
        metadatas=[faq["metadata"] for faq in sample_faqs]
    )
    
    logger.info(f"‚úÖ Cargados {len(sample_faqs)} documentos en ChromaDB")
    
    # Log de los t√≠tulos cargados para debug
    for faq in sample_faqs:
        logger.debug(f"   - {faq['id']}: {faq['title']} ({faq['metadata']['category']})")


@tool("rag_search")
def rag_search(query: str, top_k: int = 5) -> Dict:
    """
    Busca informaci√≥n relevante en la base de conocimiento de Cootradecun.
    
    Args:
        query: La pregunta o consulta del usuario
        top_k: N√∫mero de resultados a retornar (por defecto 5)
    
    Returns:
        Dict con la respuesta y las fuentes consultadas
    """
    try:
        if collection is None:
            initialize_rag()
        
        logger.info(f"üîç RAG search: '{query}' (buscando top {top_k} resultados)")
        
        # Realizar b√∫squeda sem√°ntica
        results = collection.query(
            query_texts=[query],
            n_results=top_k
        )
        
        if not results["documents"] or not results["documents"][0]:
            logger.warning(f"‚ùå No se encontraron documentos para: '{query}'")
            return {
                "answer": "No encontr√© informaci√≥n espec√≠fica sobre tu consulta en nuestra base de conocimiento.",
                "sources": [],
                "found": False
            }
        
        # Construir respuesta con los resultados m√°s relevantes
        passages = results["documents"][0]
        sources = results["ids"][0]
        metadatas = results.get("metadatas", [[]])[0]
        distances = results.get("distances", [[]])[0] if "distances" in results else []
        
        # Log de resultados encontrados
        logger.info(f"‚úÖ Encontrados {len(passages)} resultados:")
        for i, (source_id, metadata) in enumerate(zip(sources, metadatas)):
            title = metadata.get("title", "Sin t√≠tulo") if metadata else "Sin t√≠tulo"
            distance = distances[i] if i < len(distances) else "N/A"
            logger.info(f"   {i+1}. {source_id}: {title} (distancia: {distance})")
        
        # Tomar el pasaje m√°s relevante como respuesta principal
        answer = passages[0] if passages else "No encontr√© informaci√≥n relevante."
        
        # Si hay m√∫ltiples resultados relevantes, combinarlos
        if len(passages) > 1:
            # Opcional: combinar los primeros 2 resultados si son muy relevantes
            logger.debug(f"Usando resultado principal: {sources[0]}")
        
        return {
            "answer": answer,
            "sources": sources,
            "all_passages": passages,
            "found": True,
            "metadata": metadatas[0] if metadatas else {}
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error en rag_search: {e}", exc_info=True)
        return {
            "answer": f"Ocurri√≥ un error al buscar informaci√≥n: {str(e)}",
            "sources": [],
            "found": False
        }

